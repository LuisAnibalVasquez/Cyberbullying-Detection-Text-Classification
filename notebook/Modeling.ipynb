{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision(h, p, v_p):\n",
    "    plt.plot(h.history[p])\n",
    "    plt.plot(h.history[v_p])\n",
    "    plt.title('Model Precision')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(h):\n",
    "    plt.plot(h.history['loss']) \n",
    "    plt.plot(h.history['val_loss']) \n",
    "    plt.title('Model loss') \n",
    "    plt.ylabel('Loss') \n",
    "    plt.xlabel('Epoch') \n",
    "    plt.legend(['Train', 'Test'], loc='upper left') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_model(u, lr):\n",
    "    \n",
    "    inputs = keras.Input(shape=(_inputs, ))\n",
    "    \n",
    "    x = Dense(units = u,  activation=\"relu\")(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=\"final_model\")\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                   optimizer= keras.optimizers.Adam(learning_rate=lr),\n",
    "                   metrics=[tf.keras.metrics.F1Score()],\n",
    "                )\n",
    "    model.summary()\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "  def build(self, hp):\n",
    "    \n",
    "    # hp_units = hp.Int('units', min_value=32, max_value=round(_inputs/2), step=32)\n",
    "    hp_units = hp.Int('units', min_value=round(_inputs/2), max_value=_inputs, step=142)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    inputs = keras.Input(shape=(_inputs, ))\n",
    "    \n",
    "    x = Dense(units = hp_units,  activation=\"relu\")(inputs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=\"model\")\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                   optimizer= keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                   metrics=tf.keras.metrics.F1Score()\n",
    "                )\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "\n",
    "X_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "z_train = pd.read_csv('../data/processed/y_train.csv')\n",
    "z_test = pd.read_csv('../data/processed/y_test.csv')\n",
    "\n",
    "y_train = z_train['oh_label']\n",
    "y_test = z_test['oh_label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.sample(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_call_back = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "_epoch = 50\n",
    "_inputs =  len(X_train.columns)\n",
    "_rows = len(X_train. index)\n",
    "_batch = round(_rows/_epoch)\n",
    "\n",
    "print(_epoch) \n",
    "print(_inputs)\n",
    "print(_rows) \n",
    "print(_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = kt.Objective('val_loss', 'min')\n",
    "\n",
    "tunner = kt.RandomSearch(MyHyperModel(), \n",
    "                         objective = obj, \n",
    "                         seed=42,\n",
    "                         max_trials = 5, \n",
    "                         overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunner.search(np.asarray(X_train), \n",
    "              np.asarray(y_train),\n",
    "              epochs=_epoch,\n",
    "              validation_data=(np.asarray(X_test),np.asarray(y_test)), \n",
    "              batch_size= _batch,\n",
    "              callbacks=[Loss_call_back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tunner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_final_model(best_hps.get('units'), best_hps.get('learning_rate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = final_model.fit(np.asarray(X_train), \n",
    "#                           np.asarray(y_train),\n",
    "#                           epochs=_epoch,\n",
    "#                           batch_size= _batch,\n",
    "#                           validation_data = ( np.asarray(X_test), np.asarray(y_test) ),\n",
    "#                           callbacks=[Loss_call_back])\n",
    "\n",
    "history = final_model.fit(X_train, \n",
    "                          y_train,\n",
    "                          epochs=_epoch,\n",
    "                          batch_size= _batch,\n",
    "                          validation_data = ( X_test, y_test ),\n",
    "                          callbacks=[Loss_call_back])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision(history, list(history.history)[1], list(history.history)[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model.save('../models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TMLC_NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
